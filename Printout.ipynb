{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################### PART A #########################################\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from linearmodels import PanelOLS\n",
    "import numpy as np\n",
    "import patsy\n",
    "from numpy.polynomial.polynomial import polyfit\n",
    "\n",
    "# 1. Read the data\n",
    "df = pd.read_csv(\"GMdata.csv\",sep='\\t')\n",
    "\n",
    "# 2. Basic summary\n",
    "print(\"\\nDescriptive statistics:\")\n",
    "print(df.describe())\n",
    "\n",
    "# 3. Check the time dimension per firm\n",
    "#    Count how many years each firm has\n",
    "year_counts = df.groupby('index')['yr'].nunique()\n",
    "\n",
    "# 4. Identify the balanced panel\n",
    "#    Suppose we expect 4 unique years (73, 78, 83, 88) for each firm\n",
    "balanced_firms = year_counts[year_counts == 4].index\n",
    "\n",
    "# Create separate dataframes\n",
    "df_balanced = df[df['index'].isin(balanced_firms)].copy()\n",
    "df_unbalanced = df[~df['index'].isin(balanced_firms)].copy()\n",
    "\n",
    "print(\"\\nNumber of firms in balanced panel:\", len(balanced_firms))\n",
    "print(\"Number of firms (total) in unbalanced panel:\", df['index'].nunique())\n",
    "\n",
    "# 5. Summarize balanced and unbalanced panels\n",
    "print(\"\\nBalanced panel summary:\")\n",
    "print(df_balanced.describe())\n",
    "\n",
    "print(\"\\nUnbalanced panel summary:\")\n",
    "print(df_unbalanced.describe())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Balanced panel regression (no dummies)\n",
    "model_bal_basic = smf.ols(\"ldsal ~ lemp + ldnpt\",\n",
    "                          data=df_balanced).fit()\n",
    "print(\"OLS (Balanced), no dummies:\")\n",
    "print(model_bal_basic.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unbalanced panel regression (no dummies)\n",
    "model_unbal_basic = smf.ols(\"ldsal ~ lemp + ldnpt\",\n",
    "                            data=df_unbalanced).fit()\n",
    "print(\"\\nOLS (Unbalanced), no dummies:\")\n",
    "print(model_unbal_basic.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example with balanced panel and dummies\n",
    "model_bal_dummies = smf.ols(\"ldsal ~ lemp + ldnpt + C(yr)+C(sic3)\",\n",
    "                            data=df_balanced).fit()\n",
    "print(\"\\nOLS (Balanced), with dummies:\")\n",
    "print(model_bal_dummies.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example with unbalanced panel and dummies:\n",
    "model_unbal_dummies = smf.ols(\"ldsal ~ lemp + ldnpt + C(yr) + C(sic3)\",\n",
    "                              data=df_unbalanced).fit()\n",
    "print(\"\\nOLS (Unbalanced), with year & industry dummies:\")\n",
    "print(model_unbal_dummies.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Estimate the model with firm and time fixed effects (Unbalanced)\n",
    "model_unbal_fe = smf.ols(\"ldsal ~ lemp + ldnpt + C(yr) + C(index)\",\n",
    "                                       data=df_unbalanced).fit()\n",
    "print(\"\\nPanel OLS (Unbalanced), with firm and time fixed effects:\")\n",
    "print(model_unbal_fe.summary())\n",
    "df_unbalanced.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################### Creating survival variable ######################\n",
    "\n",
    "# 1. Sort by firm and year\n",
    "df_unbalanced = df_unbalanced.sort_values([\"index\",\"yr\"])\n",
    "\n",
    "# 2. Identify the next year in which the firm appears\n",
    "#    groupby(\"index\") and shift() the 'yr' column by -1 to get the next row's year\n",
    "df_unbalanced['next_yr'] = df_unbalanced.groupby('index')['yr'].shift(-1)\n",
    "\n",
    "# Because your years jump in increments of 5, define survive_next=1 \n",
    "# if next_yr == yr + 5 (i.e., the next wave). 0 otherwise.\n",
    "df_unbalanced['survive_next'] = (\n",
    "    df_unbalanced['next_yr'] == (df_unbalanced['yr'] + 5)\n",
    ").astype(int)\n",
    "\n",
    "# For the last observation of each firm (or if a firm does not appear in the next wave),\n",
    "# survive_next will be 0. If there's no subsequent row for that firm, next_yr is NaN.\n",
    "\n",
    "# 3. Drop rows with missing survive_next if you prefer to keep only firm-years\n",
    "#    that can define survival. (Optional)\n",
    "df_unbalanced = df_unbalanced.dropna(subset=['survive_next'])\n",
    "\n",
    "\n",
    "print(df_unbalanced[['index','yr','survive_next']].head(20))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop observations for yr==88\n",
    "df_unbalanced1 = df_unbalanced[df_unbalanced['yr']!=88]\n",
    "\n",
    "print(df_unbalanced1[['index','yr','survive_next']].head(15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_formula = \"survive_next ~ ldnpt + ldinv + C(yr) + C(sic3)\"\n",
    "probit_model = smf.probit(model_formula, data=df_unbalanced1).fit()\n",
    "print(probit_model.summary())\n",
    "\n",
    "df_unbalanced1['predicted_survival'] = probit_model.predict(df_unbalanced1)\n",
    "df_unbalanced1['predicted_survival'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For convenience, rename columns:\n",
    "df_unbalanced1[\"k\"] = df_unbalanced1[\"ldnpt\"]      # capital\n",
    "df_unbalanced1[\"i\"] = df_unbalanced1[\"ldinv\"]     # investment\n",
    "\n",
    "# 1) Guess labor coefficient from a naive OLS (without OP).\n",
    "naive_ols = smf.ols(\"ldsal ~ lemp + k + i + I(k**2) + I(i**2) + I(k*i)\", data=df_unbalanced1).fit()\n",
    "beta_l_guess = naive_ols.params[\"lemp\"]\n",
    "print(\"Naive OLS labor coefficient:\", beta_l_guess)\n",
    "\n",
    "# 2) Construct y_tilde = y - beta_l * l\n",
    "df_unbalanced1[\"y_tilde\"] = df_unbalanced1[\"ldsal\"] - beta_l_guess * df_unbalanced1[\"lemp\"]\n",
    "\n",
    "#get probit prediction for survival\n",
    "df_unbalanced1['predicted_survival'] = probit_model.predict(df_unbalanced1)\n",
    "\n",
    "#regress y_tilde on k lemp and predicted survival\n",
    "model_stage1 = smf.ols(\"y_tilde ~ k + predicted_survival\", data=df_unbalanced1).fit()\n",
    "print(model_stage1.summary())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_unbalanced1[\"predicted_survival_lag\"] = df_unbalanced1.groupby(\"index\")[\"predicted_survival\"].shift(1)\n",
    "\n",
    "# We'll define the second-stage dependent variable:\n",
    "#   y_tilde = beta_0 + beta_k * k_t +  E[omega_t|omega_{t-1}] + ...\n",
    "# We donâ€™t necessarily estimate a separate intercept if we let E[omega_t|omega_{t-1}] handle it.\n",
    "\n",
    "# A simple approach: polynomial in phi_hat_lag\n",
    "df_unbalanced1.dropna(subset=[\"predicted_survival_lag\"], inplace=True)  # must drop the first observation or missing lags\n",
    "\n",
    "model_stage2 = smf.ols(\n",
    "    formula=\"y_tilde ~ k + i + I(k**2) + I(i**2) + I(k*i) + I(predicted_survival) + I(predicted_survival_lag)\",\n",
    "    data=df_unbalanced1\n",
    ").fit()\n",
    "print(model_stage2.summary())\n",
    "\n",
    "\n",
    "beta_k_op = model_stage2.params[\"k\"]\n",
    "print(\"Olley-Pakes capital coefficient (selection):\", beta_k_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate market share for each firm\n",
    "df_unbalanced['market_share'] = df_unbalanced['ldsal']/df_unbalanced['ldsal'].sum()\n",
    "\n",
    "# Calculate weighted average productivity\n",
    "df_unbalanced['weighted_productivity'] = df_unbalanced['market_share'] * df_unbalanced['ldsal']\n",
    "\n",
    "# Aggregate productivity\n",
    "aggregate_productivity = df_unbalanced.groupby('yr')['weighted_productivity'].sum()\n",
    "\n",
    "# Calculate covariance between productivity and market share\n",
    "cov_capital_market_share = df_unbalanced.groupby('yr').apply(lambda x: np.cov(x['ldnpt'], x['weighted_productivity'])[0, 1])\n",
    "\n",
    "# OP decomposition for all sectors\n",
    "op_decomposition_all = pd.DataFrame({\n",
    "    'aggregate_productivity': aggregate_productivity,\n",
    "    'cov_capital_market_share': cov_capital_market_share\n",
    "})\n",
    "\n",
    "print(\"OP Decomposition for all sectors:\")\n",
    "print(op_decomposition_all)\n",
    "\n",
    "# Repeat the analysis for sic3 == 357\n",
    "df_sic3_357 = df_unbalanced[df_unbalanced['sic3'] == 357].copy()\n",
    "\n",
    "# Calculate market share for each firm in sic3 357\n",
    "df_sic3_357['market_share'] = df_sic3_357['ldsal']/df_sic3_357['ldsal'].sum()\n",
    "\n",
    "# Calculate weighted average productivity for sic3 357\n",
    "df_sic3_357['weighted_productivity'] = df_sic3_357['market_share'] * df_sic3_357['ldsal']\n",
    "\n",
    "# Aggregate productivity for sic3 357\n",
    "aggregate_productivity_sic3_357 = df_sic3_357.groupby('yr')['weighted_productivity'].sum()\n",
    "\n",
    "\n",
    "# Calculate covariance between productivity and market share for sic3 357\n",
    "cov_capital_market_share_sic3_357 = df_sic3_357.groupby('yr').apply(lambda x: np.cov(x['ldnpt'], x['weighted_productivity'])[0, 1])\n",
    "\n",
    "# OP decomposition for sic3 357\n",
    "op_decomposition_sic3_357 = pd.DataFrame({\n",
    "    'aggregate_productivity': aggregate_productivity_sic3_357,\n",
    "    'cov_capital_market_share': cov_capital_market_share_sic3_357\n",
    "})\n",
    "\n",
    "print(\"\\nOP Decomposition for sic3 357:\")\n",
    "print(op_decomposition_sic3_357)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
